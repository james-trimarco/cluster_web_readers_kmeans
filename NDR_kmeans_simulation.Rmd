---
title: "Clustering Web Readers With Kmeans"
knit: (function(input_file, encoding) {
  out_dir <- 'docs';
  rmarkdown::render(input_file,
 encoding=encoding,
 output_file=file.path(dirname(input_file), out_dir, 'index.html'))})

author: "James Trimarco"
date: "2/6/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Introduction  
Back when I was a magazine editor, I spent a lot of time looking over web traffic with my teammates. We could see patterns in the traffic and we often imagined that readers might fall into different categories: people who mostly read lifestyle stories but also read about the environment; people who read politics stories but avoided arts and culture stories, and so on. If we could sort readers into these categories, we might be able to better personalize our communications with them. 

We didn't quite have a way to quantify these hunches, though, so hunches they remained. 

After going back to school for data science, I realized that the kmeans algorithm offers a tool to do exactly the process we'd been thinking about. Kmeans starts by randomly selecting $k$ center points — $k$ is a number that we pick ourselves — and then runs an algorithm that finds all the points closest to each center, takes the average of those points to find a new center, and repeats under stable clusters emerge. (For a full description of how kmeans works, watch this [fun video by StatQuest](https://www.youtube.com/watch?v=4b5d3muPQmA)). 

Since that time, I've run the kmeans algorithm for clients to help them find the clusters hidden in their web traffic data. Usually it's clear that the results are pretty close to the publishers' hunches — "There seemed to be a group that came around every time our star blogger posted." But some of the results usually come as a surprise. 

The following workflow shows the basics of how to apply the kmeans algorithm to web traffic data using synthetic data that roughly — very roughly, actually — simulates some client data I've worked with. 

## Load libraries
```{r libraries, include=FALSE}
library(tidyverse) # for working with data
library(cluster) # clustering algorithms
library(fpc) # for visualizing clusters
library(wesanderson) # for colors
```


## Settings

```{r}
k <- 3

total_clients <- 1000
total_weblogs <- 50000

group_1_cutoff = (0:250)
group_2_cutoff = (251:600)
group_3_cutoff = (601:750)
group_4_cutoff = c(751:1000)

# total of 50000
group_1_size = 14000
group_2_size = 12000
group_3_size = 16000
group_4_size = 8000
```

## Synthesize data

### Create publication categories
```{r}
channels <- c("breakings_news", 
             "arts_culture", 
             "environment", 
             "sports", 
             "blogs", 
             "classifieds", 
             NA)

pr_group_1 <- c(.4, .075, .1, .2, .05, .1, .075)
pr_group_2 <- c(.12, .025, .05, .01, .5, .08, .175)
pr_group_3 <- c(.26, .01, .6, .01, .04, .01, .07)

```


### Create alphanumeric client codes
```{r}
r <- replicate(total_clients, paste(sample(LETTERS, 3, replace=TRUE), collapse=""))
n <- replicate(total_clients, paste(sample(c(1:9), 3, replace=TRUE), collapse=""))
client_codes <- paste0(r, n)
```

### Create column of dates
```{r}
# This function will generate a uniform sample of dates from 
# within a designated start and end date:
rand.date=function(start.day,end.day,size){   
  days=seq.Date(as.Date(start.day),as.Date(end.day),by="day")  
  pick.day=runif(n=size,min=1,max=length(days)) 
  print(head(pick.day))
  date=days[pick.day]  
}
```

### Put it together into a data frame
```{r}
group_1 <- tibble(client_code = sample(client_codes[group_1_cutoff], size=group_1_size, replace = TRUE), 
               sys_time = rand.date("2014-01-01","2018-12-31",group_1_size), 
               channel = sample(channels, size=group_1_size, prob = pr_group_1, replace = TRUE))

group_2 <- tibble(client_code = sample(client_codes[group_2_cutoff], size=group_2_size, replace = TRUE), 
               sys_time = rand.date("2014-01-01","2018-12-31",group_2_size), 
               channel = sample(channels, size=group_2_size, prob = pr_group_2, replace = TRUE))

group_3 <- tibble(client_code = sample(client_codes[group_3_cutoff], size=group_3_size, replace = TRUE), 
               sys_time = rand.date("2014-01-01","2018-12-31",group_3_size), 
               channel = sample(channels, size=group_3_size, prob = pr_group_3, replace = TRUE))

group_4 <- tibble(client_code = sample(client_codes[group_4_cutoff], size=group_4_size, replace = TRUE), 
               sys_time = rand.date("2014-01-01","2018-12-31",group_4_size), 
               channel = sample(channels, size=group_4_size, replace = TRUE))

client <- bind_rows(group_1, group_2, group_3, group_4)
```


# Part III: K-means
### Look for clusters in top 5 most-read titles by customer
```{r}
# 
client_prop <- client %>%
    select(-sys_time) %>%
    filter(!is.na(channel)) %>%
    group_by(client_code) %>%
    mutate(client_views = sum(n())) %>% 
    group_by(client_code, channel, client_views) %>%
    summarise(client_channel_views = n()) %>%
    mutate(freq = client_channel_views/client_views) %>%
    arrange(client_code, desc(freq)) 

# prep data for k-means
clients_wide <- client_prop %>%
    select(-client_views, -client_channel_views) %>%
    spread(channel, freq) 

# Replace NAs with 0
clients_wide[is.na(clients_wide)] <- 0.0

# do kmeans
k2 <- kmeans(clients_wide[2:7], centers = k, nstart = 10, algorithm = "Hartigan-Wong")

# plot kmeans
plotcluster(clients_wide[2:7], k2$cluster)

# Add cluster numbers back to original dataset
channel_cluster <- cbind(clients_wide, clusterNum = k2$cluster)

# View the data
head(channel_cluster, 50)
```


### Line plot for centers of clusters
```{r}
# Prepare data for plotting
cent <- k2$centers %>%
    data.frame() %>%
    rownames_to_column(var = "cluster") %>%
    gather(service, freq, -cluster)

(cluster_count <- length(unique(cent$cluster)))

ggplot(cent, aes(x = service, y = freq, group = cluster)) +
    geom_line(aes(color = cluster, size = 1)) +
    ggtitle(paste0("Centers of the ", cluster_count, " Service Clusters Generated by KMeans")) +
    scale_color_manual(values = wes_palette("Zissou1"))

```

